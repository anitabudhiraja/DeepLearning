{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP7oEESDEYtyB35i2LO6znb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anitabudhiraja/DeepLearning/blob/main/BinaryCrossEntropy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1IdLCII4TzH"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_circles\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "# Configuration options\n",
        "num_samples_total = 1000\n",
        "training_split = 250\n",
        "loss_function_used = BinaryCrossentropy()\n",
        "\n",
        "# Generate data\n",
        "X, targets = make_circles(n_samples = num_samples_total, factor=0.1)\n",
        "X_training = X[training_split:, :]\n",
        "X_testing = X[:training_split, :]\n",
        "Targets_training = targets[training_split:]\n",
        "Targets_testing = targets[:training_split]\n",
        "\n",
        "# Generate scatter plot for training data\n",
        "plt.scatter(X_training[:,0], X_training[:,1])\n",
        "plt.title('Nonlinear data')\n",
        "plt.xlabel('X1')\n",
        "plt.ylabel('X2')\n",
        "plt.show()\n",
        "\n",
        "# Set the input shape\n",
        "feature_vector_shape = len(X_training[0])\n",
        "input_shape = (feature_vector_shape,)\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_shape=input_shape, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(8, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Configure the model and start training\n",
        "model.compile(loss=loss_function_used, optimizer=tensorflow.keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
        "history = model.fit(X_training, Targets_training, epochs=30, batch_size=5, verbose=1, validation_split=0.2)\n",
        "\n",
        "# Test the model after training\n",
        "test_results = model.evaluate(X_testing, Targets_testing, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')\n",
        "\n",
        "# Plot decision boundary\n",
        "plot_decision_regions(X_testing, Targets_testing, clf=model, legend=2)\n",
        "plt.show()\n",
        "\n",
        "# Visualize training process\n",
        "plt.plot(history.history['loss'], label='Binary crossentropy loss (training data)')\n",
        "plt.plot(history.history['val_loss'], label='Binary crossentropy loss (validation data)')\n",
        "plt.title('Binary crossentropy loss for circles')\n",
        "plt.ylabel('Binary crossentropy loss value')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}